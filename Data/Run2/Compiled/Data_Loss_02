
Data collected from running in Measurement Regret Environment (c=0.2) , using the following algorithms:

BAM_QMDP:
nmbr_eps                    = 500
nmbr_runs                   = 5
measure_cost                = 0.2

avererage reward            = 0.69264            (with std = 0.4922505768406981)
average nmbr steps          = 6.3107999999999995            (with std = 35.50889189146854)
average nmbr measurements   = 0.5408000000000001            (with std = 2.244605836221585)

In last 1/10th of episodes:
avererage reward            = 0.7824            (with std = 0.17309604270462106)
average nmbr steps          = 2.0            (with std = 0.0)
average nmbr measurements   = 0.10800000000000001            (with std = 0.17069270634681494)


BAM_QMDP+:
nmbr_eps                    = 500
nmbr_runs                   = 5
measure_cost                = 0.2

avererage reward            = 0.74912            (with std = 0.33969872769852993)
average nmbr steps          = 2.4048000000000003            (with std = 3.5839610712171535)
average nmbr measurements   = 0.2944            (with std = 1.450147799363913)

In last 1/10th of episodes:
avererage reward            = 0.8168000000000001            (with std = 0.17363686244573762)
average nmbr steps          = 2.952            (with std = 0.7060424916391365)
average nmbr measurements   = 0.156            (with std = 0.15640971836813722)


AMRL:
nmbr_eps                    = 1000
nmbr_runs                   = 5
measure_cost                = 0.2

avererage reward            = 0.7904800000000001            (with std = 0.17748174441333395)
average nmbr steps          = 2.3476000000000004            (with std = 1.5785988217403435)
average nmbr measurements   = 0.040600000000000004            (with std = 0.1609709290524224)

In last 1/10th of episodes:
avererage reward            = 0.7799999999999998            (with std = 0.18439088914585774)
average nmbr steps          = 2.388            (with std = 2.68757437106399)
average nmbr measurements   = 0.0            (with std = 0.0)


ACNO_OTP:
nmbr_eps                    = 1000
nmbr_runs                   = 5
measure_cost                = 0.2

avererage reward            = 0.38712000000000013            (with std = 0.4367082614286109)
average nmbr steps          = 2.1544            (with std = 1.8611181155423742)
average nmbr measurements   = 2.0544000000000002            (with std = 1.9195417786544793)

In last 1/10th of episodes:
avererage reward            = 0.7919999999999999            (with std = 0.18312837027615356)
average nmbr steps          = 2.0            (with std = 0.0)
average nmbr measurements   = 0.0            (with std = 0.0)

