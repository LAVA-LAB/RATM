
Data collected from running in Measurement Regret Environment (c=0.1) , using the following algorithms:

BAM_QMDP:
nmbr_eps                    = 500
nmbr_runs                   = 5
measure_cost                = 0.1

avererage reward            = 0.80192            (with std = 0.15344938448882747)
average nmbr steps          = 2.324            (with std = 1.109443103543395)
average nmbr measurements   = 0.7888000000000002            (with std = 0.7133264049507771)

In last 1/10th of episodes:
avererage reward            = 0.7615999999999999            (with std = 0.15813108486316033)
average nmbr steps          = 2.668            (with std = 3.1311620845941524)
average nmbr measurements   = 0.5039999999999999            (with std = 0.5157363667611583)


BAM_QMDP+:
nmbr_eps                    = 500
nmbr_runs                   = 5
measure_cost                = 0.1

avererage reward            = 0.8308800000000001            (with std = 0.1818395600522615)
average nmbr steps          = 2.5088            (with std = 2.094221229956377)
average nmbr measurements   = 1.1992            (with std = 1.3286983705867932)

In last 1/10th of episodes:
avererage reward            = 0.8619999999999999            (with std = 0.07655063683601857)
average nmbr steps          = 2.4320000000000004            (with std = 0.4442701880612743)
average nmbr measurements   = 1.14            (with std = 0.3206243908376279)


AMRL:
nmbr_eps                    = 1000
nmbr_runs                   = 5
measure_cost                = 0.1

avererage reward            = 0.7998            (with std = 0.17636541611098247)
average nmbr steps          = 2.3756000000000004            (with std = 1.6667947204140048)
average nmbr measurements   = 0.04200000000000001            (with std = 0.15464798737778643)

In last 1/10th of episodes:
avererage reward            = 0.7959999999999999            (with std = 0.18542923178398815)
average nmbr steps          = 2.0            (with std = 0.0)
average nmbr measurements   = 0.0            (with std = 0.0)


ACNO_OTP:
nmbr_eps                    = 1000
nmbr_runs                   = 5
measure_cost                = 0.1

avererage reward            = 0.5952200000000001            (with std = 0.2777523206023669)
average nmbr steps          = 2.1538000000000004            (with std = 1.844468910011768)
average nmbr measurements   = 2.0538000000000003            (with std = 1.903372154887215)

In last 1/10th of episodes:
avererage reward            = 0.8119999999999998            (with std = 0.1850837648201484)
average nmbr steps          = 2.0            (with std = 0.0)
average nmbr measurements   = 0.0            (with std = 0.0)

