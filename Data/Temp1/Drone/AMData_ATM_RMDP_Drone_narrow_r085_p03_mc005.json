{"parameters": {"algo": "ATM_RMDP", "env": "Drone", "env_var": "None", "env_gen": null, "env_size": 0, "m_cost": 0.05, "nmbr_eps": "100", "nmbr_runs": "1", "f": null, "rep": "Data/Temp1/Drone/", "save": true, "alpha_plan": "0.3", "env_var_plan": 0, "alpha_measure": 0, "env_var_measure": 0, "alpha_real": "0.85", "beta": 0, "env_remake": true}, "reward_per_eps": [[-0.1, -0.25, 0.5, 0.6000000000000001, 0.6000000000000001, 0.6000000000000001, 0.55, -0.3, -0.39999999999999997, -0.44999999999999996, 0.5, 0.5, 0.6000000000000001, 0.35, -0.35, 0.55, 0.55, 0.6000000000000001, 0.45000000000000007, 0.45000000000000007, -0.1, 0.39, 0.7, -0.35, 0.6000000000000001, 0.6000000000000001, 0.5, 0.6000000000000001, 0.6772727272727272, 0.5, 0.35, 0.6000000000000001, 0.55, 0.6000000000000001, 0.55, -0.1, 0.55, -0.15000000000000002, 0.6000000000000001, 0.5, -0.5499999999999999, 0.5, 0.6000000000000001, -0.39999999999999997, 0.55, 0.55, 0.6000000000000001, 0.7, 0.5, 0.45, 0.7, -0.1, 0.7, 0.55, -0.2, 0.5, 0.55, 0.45000000000000007, -0.3, 0.5, 0.5, 0.55, 0.6000000000000001, 0.5, 0.55, 0.45000000000000007, 0.6000000000000001, -0.2, 0.6000000000000001, 0.29999999999999993, -0.44999999999999996, 0.75, 0.55, 0.5, 0.65, 0.6000000000000001, 0.55, 0.6000000000000001, -0.35, 0.55, 0.5, -0.44999999999999996, -0.2, 0.45000000000000007, -0.35, 0.5, 0.65, 0.5, 0.55, 0.5, 0.45000000000000007, 0.55, -0.25, 0.55, 0.55, -0.44999999999999996, 0.55, 0.7, 0.5, 0.55]], "steps_per_eps": [[4.0, 9.0, 14.0, 15.0, 14.0, 15.0, 16.0, 9.0, 16.0, 16.0, 16.0, 15.0, 16.0, 17.0, 9.0, 17.0, 15.0, 15.0, 15.0, 16.0, 5.0, 18.0, 14.0, 12.0, 15.0, 15.0, 17.0, 15.0, 15.0, 17.0, 18.0, 15.0, 13.0, 14.0, 15.0, 4.0, 14.0, 5.0, 14.0, 14.0, 18.0, 16.0, 16.0, 15.0, 15.0, 15.0, 13.0, 15.0, 14.0, 16.0, 16.0, 4.0, 15.0, 16.0, 9.0, 17.0, 16.0, 15.0, 12.0, 18.0, 18.0, 15.0, 14.0, 16.0, 15.0, 17.0, 14.0, 7.0, 15.0, 17.0, 15.0, 14.0, 15.0, 15.0, 15.0, 16.0, 16.0, 15.0, 11.0, 15.0, 18.0, 17.0, 7.0, 18.0, 11.0, 16.0, 15.0, 15.0, 15.0, 18.0, 16.0, 16.0, 17.0, 16.0, 17.0, 17.0, 13.0, 15.0, 18.0, 16.0]], "measurements_per_eps": [[2.0, 5.0, 10.0, 8.0, 8.0, 8.0, 9.0, 6.0, 8.0, 9.0, 10.0, 10.0, 8.0, 13.0, 7.0, 9.0, 9.0, 8.0, 11.0, 11.0, 2.0, 9.0, 6.0, 7.0, 8.0, 8.0, 10.0, 8.0, 6.0, 10.0, 13.0, 8.0, 9.0, 8.0, 9.0, 2.0, 9.0, 3.0, 8.0, 10.0, 11.0, 10.0, 8.0, 8.0, 9.0, 9.0, 8.0, 6.0, 10.0, 11.0, 6.0, 2.0, 6.0, 9.0, 4.0, 10.0, 9.0, 11.0, 6.0, 10.0, 10.0, 9.0, 8.0, 10.0, 9.0, 11.0, 8.0, 4.0, 8.0, 14.0, 9.0, 5.0, 9.0, 10.0, 7.0, 8.0, 9.0, 8.0, 7.0, 9.0, 10.0, 9.0, 4.0, 11.0, 7.0, 10.0, 7.0, 10.0, 9.0, 10.0, 11.0, 9.0, 5.0, 9.0, 9.0, 9.0, 9.0, 6.0, 10.0, 9.0]], "reward_avg": 0.35317272727272725, "steps_avg": 14.45, "measurements_avg": 8.3, "start_time": 9145.3031694, "current_time": 9145.6193687}