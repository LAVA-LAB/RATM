{"parameters": {"algo": "ATM", "env": "Drone", "env_var": "None", "env_gen": null, "env_size": 0, "m_cost": 0.1, "nmbr_eps": "100", "nmbr_runs": "1", "f": null, "rep": "Data/Temp1/Drone/", "save": true, "alpha_plan": "0.5", "env_var_plan": 0, "alpha_measure": 0, "env_var_measure": 0, "alpha_real": "0.95", "beta": 0, "env_remake": true}, "reward_per_eps": [[0.6, -0.1, -0.1, -0.1, 0.9, -0.2, -0.2, -0.1, 0.0, 0.8, -0.1, -0.1, -0.1, -0.2, -0.1, 0.7, 0.6, -0.1, -0.1, 0.9, 0.0, -0.1, 0.7, -0.4, -0.1, 0.8, -0.1, 0.6, -0.1, 0.8, -0.1, 0.6, -0.1, -0.1, 0.0, -0.1, -0.1, -0.1, 0.7, -0.1, 0.0, -0.1, -0.1, 0.6, 0.9, 0.7, -0.2, -0.1, 0.9, -0.1, -0.1, 0.5, 0.7, -0.1, 0.0, -0.1, 0.6591836734693877, 0.0, -0.1, -0.1, 0.9, -0.1, -0.1, 0.7, -0.1, -0.1, 0.73, 0.7, -0.30000000000000004, -0.2, -0.2, 0.7, 0.6, 0.0, -0.1, 0.8, -0.1, 0.6, -0.2, -0.1, -0.2, 0.0, -0.4, 0.7, -0.1, 0.7, -0.1, 0.6425287356321838, -0.1, 0.9, 0.7, -0.1, 0.7, -0.1, -0.1, 0.0, -0.1, -0.1, -0.1, -0.1]], "steps_per_eps": [[16.0, 4.0, 7.0, 12.0, 17.0, 11.0, 14.0, 4.0, 3.0, 12.0, 12.0, 5.0, 4.0, 10.0, 11.0, 14.0, 15.0, 7.0, 8.0, 28.0, 3.0, 7.0, 14.0, 13.0, 12.0, 12.0, 11.0, 14.0, 12.0, 12.0, 4.0, 15.0, 11.0, 4.0, 3.0, 8.0, 9.0, 7.0, 13.0, 8.0, 3.0, 5.0, 7.0, 16.0, 12.0, 13.0, 16.0, 11.0, 21.0, 9.0, 9.0, 16.0, 14.0, 12.0, 3.0, 23.0, 15.0, 3.0, 12.0, 7.0, 17.0, 9.0, 7.0, 15.0, 11.0, 4.0, 13.0, 14.0, 17.0, 11.0, 10.0, 14.0, 17.0, 3.0, 5.0, 12.0, 7.0, 13.0, 23.0, 4.0, 10.0, 3.0, 16.0, 13.0, 12.0, 14.0, 7.0, 15.0, 10.0, 15.0, 14.0, 17.0, 16.0, 4.0, 11.0, 3.0, 22.0, 16.0, 7.0, 9.0]], "measurements_per_eps": [[4.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 4.0, 1.0, 1.0, 1.0, 0.0, 1.0, 3.0, 4.0, 1.0, 2.0, 1.0, 4.0, 1.0, 2.0, 1.0, 4.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 3.0, 1.0, 0.0, 1.0, 1.0, 4.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 5.0, 3.0, 1.0, 0.0, 1.0, 3.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 3.0, 2.0, 2.0, 3.0, 4.0, 0.0, 1.0, 2.0, 1.0, 4.0, 2.0, 1.0, 2.0, 0.0, 4.0, 3.0, 1.0, 3.0, 1.0, 3.0, 1.0, 1.0, 3.0, 1.0, 3.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]], "reward_avg": 0.16331712409101562, "steps_avg": 10.93, "measurements_avg": 1.64, "start_time": 16199.6175986, "current_time": 16209.9137751}