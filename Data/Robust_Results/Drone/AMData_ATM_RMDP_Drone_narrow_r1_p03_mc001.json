{"parameters": {"algo": "ATM_RMDP", "env": "Drone", "env_var": "None", "env_gen": null, "env_size": 0, "m_cost": 0.01, "nmbr_eps": "100", "nmbr_runs": "1", "f": null, "rep": "Data/Temp1/Drone/", "save": true, "alpha_plan": "0.3", "env_var_plan": 0, "alpha_measure": 0, "env_var_measure": 0, "alpha_real": "1.00", "beta": 0, "env_remake": true}, "reward_per_eps": [[0.88, 0.65, -0.13999999999999999, 0.88, 0.87, 0.89, 0.89, 0.89, 0.85, 0.88, 0.9, 0.87, 0.87, 0.9, 0.88, -0.12999999999999998, 0.88, 0.87, 0.89, 0.88, 0.9, 0.88, 0.84, 0.88, 0.86, 0.87, 0.88, 0.87, 0.88, 0.89, 0.89, 0.89, 0.88, 0.87, -0.02, 0.88, 0.87, 0.88, -0.11999999999999998, 0.91, 0.87, -0.10999999999999999, 0.89, 0.86, 0.89, 0.88, 0.89, 0.87, -0.11999999999999998, 0.88, 0.9, 0.9, 0.9, -0.09999999999999999, 0.9, 0.88, 0.88, 0.87, 0.87, -0.08, 0.89, -0.11999999999999998, -0.060000000000000005, 0.89, 0.87, 0.9, 0.88, 0.92, 0.89, 0.86, 0.89, 0.88, 0.87, 0.91, 0.87, 0.89, 0.9, 0.85, 0.88, 0.89, 0.91, -0.10999999999999999, 0.8382716049382716, -0.11999999999999998, 0.86, -0.06999999999999998, 0.88, 0.89, 0.89, 0.87, 0.88, 0.87, 0.9, 0.88, 0.87, 0.88, 0.88, 0.88, 0.88, 0.88]], "steps_per_eps": [[15.0, 15.0, 16.0, 14.0, 15.0, 14.0, 14.0, 14.0, 16.0, 14.0, 14.0, 14.0, 14.0, 13.0, 14.0, 17.0, 15.0, 15.0, 14.0, 15.0, 15.0, 14.0, 17.0, 14.0, 15.0, 15.0, 14.0, 15.0, 14.0, 14.0, 15.0, 14.0, 14.0, 15.0, 3.0, 17.0, 14.0, 15.0, 15.0, 12.0, 15.0, 15.0, 16.0, 15.0, 14.0, 16.0, 14.0, 16.0, 16.0, 17.0, 15.0, 13.0, 13.0, 11.0, 13.0, 14.0, 15.0, 16.0, 15.0, 9.0, 13.0, 15.0, 9.0, 15.0, 15.0, 14.0, 15.0, 13.0, 15.0, 16.0, 14.0, 14.0, 15.0, 13.0, 15.0, 14.0, 13.0, 16.0, 13.0, 17.0, 12.0, 15.0, 14.0, 16.0, 16.0, 16.0, 14.0, 14.0, 14.0, 14.0, 14.0, 16.0, 14.0, 15.0, 16.0, 15.0, 15.0, 16.0, 14.0, 14.0]], "measurements_per_eps": [[12.0, 12.0, 14.0, 12.0, 13.0, 11.0, 11.0, 11.0, 15.0, 12.0, 10.0, 13.0, 13.0, 10.0, 12.0, 13.0, 12.0, 13.0, 11.0, 12.0, 10.0, 12.0, 16.0, 12.0, 14.0, 13.0, 12.0, 13.0, 12.0, 11.0, 11.0, 11.0, 12.0, 13.0, 2.0, 12.0, 13.0, 12.0, 12.0, 9.0, 13.0, 11.0, 11.0, 14.0, 11.0, 12.0, 11.0, 13.0, 12.0, 12.0, 10.0, 10.0, 10.0, 10.0, 10.0, 12.0, 12.0, 13.0, 13.0, 8.0, 11.0, 12.0, 6.0, 11.0, 13.0, 10.0, 12.0, 8.0, 11.0, 14.0, 11.0, 12.0, 13.0, 9.0, 13.0, 11.0, 10.0, 15.0, 12.0, 11.0, 9.0, 11.0, 10.0, 12.0, 14.0, 12.0, 12.0, 11.0, 11.0, 13.0, 12.0, 13.0, 10.0, 12.0, 13.0, 12.0, 12.0, 12.0, 12.0, 12.0]], "reward_avg": 0.7513827160493824, "steps_avg": 14.39, "measurements_avg": 11.62, "start_time": 2423.0711846, "current_time": 2423.2998397}